{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Model Fit \n",
    "There are this kinds of problems you can face when trying to fit a problem to a model\n",
    "\n",
    "1. Training doesn't get started: your training loss does not go down \n",
    "2. Training starts but the model does not meaningfully predict values and cannot beat the metrics (baseline) you decide for random classifier \n",
    "3. Training and validation loss keep going down and we cannot seem to overfit the model to get a point where we need to stop training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Tuning the gradient descent\n",
    "In the first problem you should tinker with the learning rate or batch size used for training and gradient descent to make training rate go down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 927.8696 - accuracy: 0.3262 - val_loss: 2.0895 - val_accuracy: 0.2468\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8464 - accuracy: 0.2275 - val_loss: 2.1864 - val_accuracy: 0.2110\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.8098 - accuracy: 0.2179 - val_loss: 2.2713 - val_accuracy: 0.1664\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3579 - accuracy: 0.2062 - val_loss: 2.2027 - val_accuracy: 0.2037\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.7499 - accuracy: 0.2333 - val_loss: 2.2303 - val_accuracy: 0.2522\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.5999 - accuracy: 0.2364 - val_loss: 2.1125 - val_accuracy: 0.2407\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.6563 - accuracy: 0.2415 - val_loss: 2.2685 - val_accuracy: 0.2048\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3784 - accuracy: 0.2447 - val_loss: 2.1839 - val_accuracy: 0.2717\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3688 - accuracy: 0.2407 - val_loss: 2.1919 - val_accuracy: 0.1957\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3805 - accuracy: 0.2263 - val_loss: 2.0358 - val_accuracy: 0.2340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x10608b2d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),  # just too much learning rate \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# due to the large learning rate 1.0 we can see that the accuracy and loss are both stand still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.9118 - val_loss: 0.1423 - val_accuracy: 0.9588\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1246 - accuracy: 0.9648 - val_loss: 0.1243 - val_accuracy: 0.9659\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9740 - val_loss: 0.1203 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9795 - val_loss: 0.1538 - val_accuracy: 0.9662\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9814 - val_loss: 0.1867 - val_accuracy: 0.9685\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9855 - val_loss: 0.1669 - val_accuracy: 0.9736\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9865 - val_loss: 0.1895 - val_accuracy: 0.9731\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9888 - val_loss: 0.1856 - val_accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9897 - val_loss: 0.2393 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9905 - val_loss: 0.2213 - val_accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28cf29fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),  # just too much learning rate \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# here the loss starts to go down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
