{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Classification \n",
    "We try to classify movies in IMDB database into either positive reviews or negative reviews. This is an example of a \n",
    "binary classification problem in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) \n",
    "# here we keep only the top 10k words in each review of imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape # vector of 25000 reviews, each review is a list of integers\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewing the data \n",
    "\n",
    "def decode(review):  # is a vector of integers which is an imdb review. \n",
    "    word_index = imdb.get_word_index()\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in review])\n",
    "    return decoded_review\n",
    "\n",
    "# print(decode(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare your data \n",
    "The data in database is a series of integers of different length. These need to be convereted to a tensor \n",
    "which will have values of same length so that neural network can do its job. There are 2 ways of converting that \n",
    "array of integeres to a tensor: \n",
    "1. First is to convert all integers into same length (padding) we need to have tensor with shape (samples, max_length). you start of the NN with a layer that handle such integers (embedding layer)\n",
    "2. Multi hot encoding - turn you lists into a series of 1 and 0. This means if we have vector [8,5,6] then the 10k vector will have first three elments as 1s and all other as 0s [1,1,1,0 ...., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following the vectorization of the data\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):  # we vectorize each integer in 10k dim. vector\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1  # set results to 1 where we have a sequence of integers and rest are zeros in the 10k \n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [0. 1. 1. ... 0. 0. 0.]\n",
      "y_train: [1. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train[0]}\")\n",
    "print(f\"y_train: {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build your model \n",
    "The next step is about building the model (neural network) so that it can be later trained. \n",
    "The dataset we have is a set of vectors as inputs and the output is a scalar (1 or 0). This is the simplest problem set in DL this will be a series of densely packed layers with a `relu` activation function. \n",
    "\n",
    "**The architrecture decisions you need to take** \n",
    "* how many layers to use \n",
    "* how many units to choose in each layer. \n",
    "\n",
    "Priciples for making architecture decisions will be taken up later for now we will choose: \n",
    "* two intermediate layers with 16 units each \n",
    "* A third layer will output he scalar (sentiment of the review positive / negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "mr_model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
